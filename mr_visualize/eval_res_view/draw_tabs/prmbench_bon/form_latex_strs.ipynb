{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mr_eval.utils.utils import *\n",
    "import os\n",
    "\n",
    "def list_jsonl_files(folder_path):\n",
    "    \"\"\"\n",
    "    Âàó‰∏æÊñá‰ª∂Â§π‰∏≠ÁöÑÊâÄÊúâ .jsonl Êñá‰ª∂\n",
    "    Args:\n",
    "        folder_path (str): Êñá‰ª∂Â§πË∑ØÂæÑ\n",
    "    Returns:\n",
    "        List[str]: ÊâÄÊúâ .jsonl Êñá‰ª∂ÁöÑË∑ØÂæÑ\n",
    "    \"\"\"\n",
    "    return [f for f in os.listdir(folder_path) if f.endswith(\".jsonl\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model names\n",
    "prm_model_name_dict = dict(\n",
    "    skyworkprm_1_5B=\"\\\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B}{Skywork-PRM-1.5B}\",\n",
    "    skyworkprm_7B=\"\\\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B}{Skywork-PRM-7B}\",\n",
    "    llemma7b_prm_prm800k=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf}{Llemma-PRM800k-7B}\",\n",
    "    llemma7b_prm_metamath=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf}{Llemma-MetaMath-7B}\",\n",
    "    llemma7b_oprm_prm800k=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf}{Llemma-oprm-7B}\",\n",
    "    mathminos_mistral=\"\\\\href{https://github.com/KbsdJames/MATH-Minos}{MATHMinos-Mistral-7B}\",\n",
    "    mathshepherd=\"\\\\href{https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm}{MathShepherd-Mistral-7B}\",\n",
    "    reasoneval7b=\"\\\\href{https://huggingface.co/GAIR/ReasonEval-7B}{ReasonEval-7B}\",\n",
    "    llama3_1_8b_prm_mistral=\"\\\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data}{RLHFlow-PRM-Mistral-8B}\",\n",
    "    llama3_1_8b_prm_deepseek=\"\\\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data}{RLHFlow-PRM-Deepseek-8B}\",\n",
    "    reasoneval34b=\"\\\\href{https://huggingface.co/GAIR/ReasonEval-34B}{ReasonEval-34B}\",\n",
    ")\n",
    "close_model_name_dict = dict(\n",
    "    gpt4o=\"\\\\href{https://openai.com/index/hello-gpt-4o/}{GPT-4o}\",\n",
    "    o1mini=\"\\\\href{https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/}{o1-mini}$^\\dagger$\",\n",
    "    \n",
    "    gemini_2_flash=\"\\\\href{https://deepmind.google/technologies/gemini/flash/}{Gemini-2.0-flash-exp}\",\n",
    "    gemini_2_thinking=\"\\\\href{https://ai.google.dev/gemini-api/docs/thinking-mode}{Gemini-2.0-thinking-exp-1219}\",\n",
    ")\n",
    "    \n",
    "open_model_name_dict = dict(\n",
    "    o1preview=\"\\\\href{https://openai.com/index/introducing-openai-o1-preview/}{o1-preview}$^\\dagger$\",\n",
    "    qwen_qwq=\"\\\\href{https://huggingface.co/Qwen/QwQ-32B-Preview}{QwQ-Preview-32B}\",\n",
    ")\n",
    "\n",
    "all_model_name_dict = {**prm_model_name_dict, **close_model_name_dict, **open_model_name_dict}\n",
    "datasets = [\"gsm8k\", \"math\", \"olympiadbench\", \"mmlu\"]\n",
    "datasets_dict = dict(\n",
    "    gsm8k=\"GSM8k\",\n",
    "    math=\"Math\",\n",
    "    olympiadbench=\"OlympiadBench\",\n",
    "    mmlu=\"MMLU\",\n",
    ")\n",
    "\n",
    "\n",
    "## File paths\n",
    "res_dir = \"/mnt/petrelfs/songmingyang/code/reasoning/MR_Hallucination/mr_eval/scripts/logs/prmbench_bon\"\n",
    "res_files = list_jsonl_files(res_dir)\n",
    "res_names = [f.split(\".\")[0] for f in res_files]\n",
    "res_paths = [os.path.join(res_dir, f) for f in res_files]\n",
    "file_dict = dict(zip(res_names, res_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_dict(file_dict,model_lists=None):\n",
    "    res_dict = {}\n",
    "    if not model_lists:\n",
    "        for model_name, file_path in file_dict.items():\n",
    "            res_dict[model_name] = process_jsonl(file_path)[-1]\n",
    "    else:\n",
    "        for model_name in model_lists:\n",
    "            file_path = file_dict[model_name]\n",
    "            res_dict[model_name] = process_jsonl(file_path)[-1]\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_res_str(model_dict, datasets_dict, res_dict):\n",
    "    res = \"\"\n",
    "    example_model_name, example_res = list(res_dict.items())[0]\n",
    "    res += f\"pass@8\"\n",
    "    for dataset_name, dataset in datasets_dict.items():\n",
    "        pass_at_n = example_res[\"pass_at_n\"].get(dataset_name, \"N/A\")\n",
    "        res += f\" & {pass_at_n*100 :.2f}\" if pass_at_n != \"N/A\" else \"& N/A\"\n",
    "    res += \"\\\\\\\\\\n\"\n",
    "    res += f\"maj@8\"\n",
    "    for dataset_name, dataset in datasets_dict.items():\n",
    "        maj_at_n = example_res[\"maj_of_n\"].get(dataset_name, \"N/A\")\n",
    "        res += f\" & {maj_at_n*100 :.2f}\" if maj_at_n != \"N/A\" else \"& N/A\"\n",
    "    res += \"\\\\\\\\\\n \\midrule \\n\"\n",
    "    \n",
    "    for model_name, res_item in res_dict.items():\n",
    "        model = model_dict[model_name]\n",
    "        res += f\"{model}\"\n",
    "        for dataset_name, dataset in datasets_dict.items():\n",
    "            if dataset_name in res_item['prm_bon']:\n",
    "                res += f\" & {res_item['prm_bon'][dataset_name]*100:.2f}\"\n",
    "            else:\n",
    "                res += \"& N/A \"\n",
    "        res += \"\\\\\\\\\\n\"\n",
    "    return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass@8 & 94.77& N/A& N/A& N/A\\\\\n",
      "maj@8 & 91.66& N/A& N/A& N/A\\\\\n",
      " \\midrule \n",
      "\\href{https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm}{MathShepherd-Mistral-7B} & 90.45& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data}{RLHFlow-PRM-Deepseek-8B} & 90.60& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B}{Skywork-PRM-1.5B} & 90.75& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf}{Llemma-oprm-7B} & 89.92& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data}{RLHFlow-PRM-Mistral-8B} & 90.45& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/GAIR/ReasonEval-7B}{ReasonEval-7B} & 90.45& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B}{Skywork-PRM-7B} & 91.74& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/GAIR/ReasonEval-34B}{ReasonEval-34B} & 90.30& N/A & N/A & N/A \\\\\n",
      "\\href{https://github.com/KbsdJames/MATH-Minos}{MATHMinos-Mistral-7B} & 88.63& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf}{Llemma-PRM800k-7B} & 89.99& N/A & N/A & N/A \\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf}{Llemma-MetaMath-7B} & 89.99& N/A & N/A & N/A \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "res_dict = get_res_dict(file_dict,)\n",
    "prm_str = get_res_str(all_model_name_dict, datasets_dict, res_dict,)\n",
    "res_str += prm_str\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model names\n",
    "prm_model_name_dict = dict(\n",
    "    skyworkprm_1_5B=\"[Skywork-PRM-1.5B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B)\",\n",
    "    skyworkprm_7B=\"[Skywork-PRM-7B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B)\",\n",
    "    llemma7b_prm_prm800k=\"[Llemma-PRM800k-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf)\",\n",
    "    llemma7b_prm_metamath=\"[Llemma-MetaMath-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf)\",\n",
    "    llemma7b_oprm_prm800k=\"[Llemma-oprm-7B](https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf)\",\n",
    "    mathminos_mistral=\"[MATHMinos-Mistral-7B](https://github.com/KbsdJames/MATH-Minos)\",\n",
    "    mathshepherd=\"[MathShepherd-Mistral-7B](https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm)\",\n",
    "    reasoneval7b=\"[ReasonEval-7B](https://huggingface.co/GAIR/ReasonEval-7B)\",\n",
    "    llama3_1_8b_prm_mistral=\"[RLHFlow-PRM-Mistral-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data)\",\n",
    "    llama3_1_8b_prm_deepseek=\"[RLHFlow-PRM-Deepseek-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data)\",\n",
    "    reasoneval34b=\"[ReasonEval-34B](https://huggingface.co/GAIR/ReasonEval-34B)\",\n",
    "    qwen_prm7b=\"[Qwen2.5-Math-PRM-7B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B)\",\n",
    "    qwen_prm72b=\"[Qwen2.5-Math-PRM-72B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-72B)\",\n",
    ")\n",
    "\n",
    "close_model_name_dict = dict(\n",
    "    gpt4o=\"[GPT-4o](https://openai.com/index/hello-gpt-4o/)\",\n",
    "    o1mini=\"[o1-mini](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)\\\\$^\\dagger$\",\n",
    "    \n",
    "    gemini_2_flash=\"[Gemini-2.0-flash-exp](https://deepmind.google/technologies/gemini/flash/)\",\n",
    "    gemini_2_thinking=\"[Gemini-2.0-thinking-exp-1219](https://ai.google.dev/gemini-api/docs/thinking-mode)\",\n",
    ")\n",
    "\n",
    "open_model_name_dict = dict(\n",
    "    o1preview=\"[o1-preview](https://openai.com/index/introducing-openai-o1-preview/)\\\\$^\\dagger$\",\n",
    "    qwen_qwq=\"[QwQ-Preview-32B](https://huggingface.co/Qwen/QwQ-32B-Preview)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_str(model_dict, classification_dict, res_dict):\n",
    "    res_str = \"\"\n",
    "    avg_res_list = []\n",
    "\n",
    "    # Ë°®Â§¥ÈÉ®ÂàÜ\n",
    "    header_row = \"| Model | Overall\"\n",
    "    separator_row = \"|-------|-------\"\n",
    "    for big_classification, current_classification_dict in classification_dict.items():\n",
    "        for classification, display_classification_name in current_classification_dict.items():\n",
    "            header_row += f\"| {display_classification_name} \"\n",
    "            separator_row += \"|-------\"\n",
    "        header_row += f\"| Avg ({big_classification}) \"\n",
    "        separator_row += \"|-------\"\n",
    "    header_row += \" |\\n\"\n",
    "    separator_row += \" |\\n\"\n",
    "    res_str += header_row + separator_row\n",
    "\n",
    "    # Êï∞ÊçÆÈÉ®ÂàÜ\n",
    "    for idx, (model_name, model_display_name) in enumerate(model_dict.items()):\n",
    "        temp_str = f\"| {model_display_name} \"\n",
    "        current_res_dict = res_dict[model_name]\n",
    "\n",
    "        # ËÆ°ÁÆó PRM Score\n",
    "        prm_score = get_prmscore_from_current_res_dict(current_res_dict)\n",
    "        all_model_scores = sorted([get_prmscore_from_current_res_dict(res) for res in res_dict.values()], reverse=True)\n",
    "        if idx == 0:\n",
    "            avg_res_list.append(sum(all_model_scores) / len(all_model_scores))\n",
    "        if prm_score == max(all_model_scores):\n",
    "            temp_str += f\"| **{prm_score * 100:.1f}** \"\n",
    "        elif prm_score == all_model_scores[1]:\n",
    "            temp_str += f\"| _{prm_score * 100:.1f}_ \"\n",
    "        else:\n",
    "            temp_str += f\"| {prm_score * 100:.1f} \"\n",
    "\n",
    "        # ÂàÜÁ±ªÊåáÊ†áÈÉ®ÂàÜ\n",
    "        for big_classification, current_classification_dict in classification_dict.items():\n",
    "            all_avt = sorted([get_avg_prmscore_from_current_res_dict(res, list(current_classification_dict.keys())) for res in res_dict.values()], reverse=True)\n",
    "            avg = []\n",
    "            for classification, display_classification_name in current_classification_dict.items():\n",
    "                prm_score = get_prmscore_from_current_res_dict(current_res_dict, classification)\n",
    "                all_prm_scores = sorted([get_prmscore_from_current_res_dict(res, classification) for res in res_dict.values()], reverse=True)\n",
    "                if idx == 0:\n",
    "                    avg_res_list.append(sum(all_prm_scores) / len(all_prm_scores))\n",
    "                avg.append(prm_score)\n",
    "                if prm_score == max(all_prm_scores):\n",
    "                    temp_str += f\"| **{prm_score * 100:.1f}** \"\n",
    "                elif prm_score == all_prm_scores[1]:\n",
    "                    temp_str += f\"| _{prm_score * 100:.1f}_ \"\n",
    "                else:\n",
    "                    temp_str += f\"| {prm_score * 100:.1f} \"\n",
    "\n",
    "            # ÂàÜÁ±ªÊåáÊ†áÁöÑÂπ≥ÂùáÂàÜ\n",
    "            avg_score = sum(avg) / len(avg)\n",
    "            if avg_score == max(all_avt):\n",
    "                temp_str += f\"| **{avg_score * 100:.1f}** \"\n",
    "            elif avg_score == all_avt[1]:\n",
    "                temp_str += f\"| _{avg_score * 100:.1f}_ \"\n",
    "            else:\n",
    "                temp_str += f\"| {avg_score * 100:.1f} \"\n",
    "            if idx == 0:\n",
    "                avg_res_list.append(sum(all_avt) / len(all_avt))\n",
    "\n",
    "        # Ë°åÁªìÊùü\n",
    "        temp_str += \"\\n\"\n",
    "        res_str += temp_str\n",
    "\n",
    "    # Âπ≥ÂùáË°å\n",
    "    avg_res_str = \"| **Avg.** \"\n",
    "    for res in avg_res_list:\n",
    "        avg_res_str += f\"| **{res * 100:.1f}** \"\n",
    "    avg_res_str += \"|\\n\"\n",
    "    res_str += avg_res_str\n",
    "\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | Overall| NR. | NCL. | Avg (simplicity) | ES. | SC. | DC. | CI. | Avg (soundness) | PS. | DR. | MS. | Avg (sensitivity)  |\n",
      "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------- |\n",
      "| [Skywork-PRM-1.5B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B) | 31.5 | 31.2 | 35.6 | 33.4 | 32.3 | 25.6 | 25.7 | 29.9 | 28.4 | 32.8 | 32.0 | 80.9 | 48.6 \n",
      "| [Skywork-PRM-7B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B) | 36.2 | 35.7 | 41.2 | 38.4 | 36.7 | 29.1 | 30.6 | 34.4 | 32.7 | 36.8 | 37.4 | 88.8 | 54.3 \n",
      "| [Llemma-PRM800k-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf) | 52.0 | 49.3 | 53.4 | 51.4 | 56.4 | 47.1 | 46.7 | 53.3 | 50.9 | 51.0 | 53.5 | 93.6 | 66.0 \n",
      "| [Llemma-MetaMath-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf) | 50.5 | 50.2 | 50.5 | 50.3 | 51.9 | 47.6 | 44.4 | 52.1 | 49.0 | 50.5 | 51.3 | 96.0 | 66.0 \n",
      "| [Llemma-oprm-7B](https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf) | 50.3 | 48.7 | 49.3 | 49.0 | 54.2 | 46.8 | 44.5 | 53.5 | 49.8 | 49.2 | 51.3 | 91.8 | 64.1 \n",
      "| [MATHMinos-Mistral-7B](https://github.com/KbsdJames/MATH-Minos) | 54.2 | 48.8 | 54.0 | 51.4 | 57.0 | 52.1 | 50.7 | 57.8 | 54.4 | 52.8 | 55.8 | 91.1 | 66.5 \n",
      "| [MathShepherd-Mistral-7B](https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm) | 47.0 | 44.0 | 50.3 | 47.1 | 49.4 | 44.5 | 41.3 | 47.7 | 45.7 | 47.2 | 48.6 | 86.1 | 60.7 \n",
      "| [ReasonEval-7B](https://huggingface.co/GAIR/ReasonEval-7B) | 60.1 | **61.0** | 50.1 | **55.6** | 62.1 | 65.9 | 61.5 | 66.0 | 63.9 | 55.7 | 58.0 | 99.5 | 71.1 \n",
      "| [RLHFlow-PRM-Mistral-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data) | 54.4 | 46.1 | 47.3 | 46.7 | 56.6 | 55.1 | 54.4 | 63.8 | 57.5 | 51.5 | 56.2 | 97.9 | 68.5 \n",
      "| [RLHFlow-PRM-Deepseek-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data) | 54.2 | 46.4 | 48.9 | 47.6 | 55.7 | 55.0 | 53.2 | 66.2 | 57.5 | 49.0 | 55.4 | **99.8** | 68.1 \n",
      "| [ReasonEval-34B](https://huggingface.co/GAIR/ReasonEval-34B) | 60.5 | _54.8_ | 48.1 | 51.5 | 66.4 | 60.3 | 57.8 | 67.5 | 63.0 | _57.7_ | 64.3 | 97.2 | 73.1 \n",
      "| [Qwen2.5-Math-PRM-7B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B) | _65.5_ | 49.0 | _55.1_ | 52.1 | _71.8_ | _67.3_ | _66.3_ | _78.5_ | _71.0_ | 57.6 | _69.1_ | _99.7_ | _75.5_ \n",
      "| [Qwen2.5-Math-PRM-72B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-72B) | **68.2** | 50.4 | **58.8** | _54.6_ | **73.7** | **71.1** | **72.2** | **78.6** | **73.9** | **60.3** | **71.2** | 99.4 | **77.0** \n",
      "| **Avg.** | **52.7** | **47.4** | **49.4** | **48.4** | **55.7** | **51.3** | **50.0** | **57.6** | **53.7** | **50.2** | **54.2** | **94.0** | **66.1** |\n",
      "| Model | Overall| NR. | NCL. | Avg (simplicity) | ES. | SC. | DC. | CI. | Avg (soundness) | PS. | DR. | MS. | Avg (sensitivity)  |\n",
      "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------- |\n",
      "| [GPT-4o](https://openai.com/index/hello-gpt-4o/) | 66.8 | 57.0 | 62.4 | 59.7 | 72.0 | _69.7_ | 70.7 | 71.1 | 70.9 | **62.5** | 65.7 | 99.2 | **75.8** \n",
      "| [o1-mini](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)\\$^\\dagger$ | _68.8_ | 65.6 | _63.7_ | _64.6_ | **74.5** | 67.7 | **73.8** | **72.3** | **72.1** | _61.8_ | 64.8 | **100.0** | _75.5_ \n",
      "| [Gemini-2.0-flash-exp](https://deepmind.google/technologies/gemini/flash/) | 66.0 | _67.2_ | 58.1 | 62.7 | 70.4 | 65.7 | 66.0 | 67.3 | 67.3 | 61.8 | **66.2** | 98.2 | 75.4 \n",
      "| [Gemini-2.0-thinking-exp-1219](https://ai.google.dev/gemini-api/docs/thinking-mode) | **68.8** | **68.5** | **63.8** | **66.2** | _72.9_ | **71.3** | _71.0_ | _71.8_ | _71.8_ | 60.3 | _65.7_ | _99.8_ | 75.3 \n",
      "| **Avg.** | **67.6** | **64.6** | **62.0** | **63.3** | **72.4** | **68.6** | **70.4** | **70.7** | **70.5** | **61.6** | **65.6** | **99.3** | **75.5** |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "\n",
    "## PRMs\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(prm_model_name_dict.keys()))\n",
    "prm_str = get_res_str(prm_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += prm_str\n",
    "\n",
    "## Close Models\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(close_model_name_dict.keys()))\n",
    "close_str = get_res_str(close_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += close_str\n",
    "\n",
    "\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form HTML str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm_model_dict = {\n",
    "    \"skyworkprm_1_5B\": {\"Name\": \"Skywork-PRM-1.5B\", \"Source\": \"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\", \"Class\": \"PRM\"},\n",
    "    \"skyworkprm_7B\": {\"Name\": \"Skywork-PRM-7B\", \"Source\": \"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_prm_prm800k\": {\"Name\": \"Llemma-PRM800k-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_prm_metamath\": {\"Name\": \"Llemma-MetaMath-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_oprm_prm800k\": {\"Name\": \"Llemma-oprm-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"mathminos_mistral\": {\"Name\": \"MATHMinos-Mistral-7B\", \"Source\": \"https://github.com/KbsdJames/MATH-Minos\", \"Class\": \"PRM\"},\n",
    "    \"mathshepherd\": {\"Name\": \"MathShepherd-Mistral-7B\", \"Source\": \"https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm\", \"Class\": \"PRM\"},\n",
    "    \"reasoneval7b\": {\"Name\": \"ReasonEval-7B\", \"Source\": \"https://huggingface.co/GAIR/ReasonEval-7B\", \"Class\": \"PRM\"},\n",
    "    \"llama3_1_8b_prm_mistral\": {\"Name\": \"RLHFlow-PRM-Mistral-8B\", \"Source\": \"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data\", \"Class\": \"PRM\"},\n",
    "    \"llama3_1_8b_prm_deepseek\": {\"Name\": \"RLHFlow-PRM-Deepseek-8B\", \"Source\": \"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\", \"Class\": \"PRM\"},\n",
    "    \"reasoneval34b\": {\"Name\": \"ReasonEval-34B\", \"Source\": \"https://huggingface.co/GAIR/ReasonEval-34B\", \"Class\": \"PRM\"},\n",
    "    \"gpt4o\": {\"Name\": \"GPT-4o\", \"Source\": \"https://openai.com/index/hello-gpt-4o/\", \"Class\": \"LM-C\"},\n",
    "    \"o1mini\": {\"Name\": \"o1-mini\", \"Source\": \"https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/\", \"Class\": \"LM-C\"},\n",
    "    \"gemini_2_flash\": {\"Name\": \"Gemini-2.0-flash-exp\", \"Source\": \"https://deepmind.google/technologies/gemini/flash/\", \"Class\": \"LM-C\"},\n",
    "    \"gemini_2_thinking\": {\"Name\": \"Gemini-2.0-thinking-exp-1219\", \"Source\": \"https://ai.google.dev/gemini-api/docs/thinking-mode\", \"Class\": \"LM-C\"},\n",
    "    # \"o1preview\": {\"Name\": \"o1-preview\", \"Source\": \"https://openai.com/index/introducing-openai-o1-preview/\", \"Class\": \"LM-C\"},\n",
    "    \"qwen_qwq\": {\"Name\": \"QwQ-Preview-32B\", \"Source\": \"https://huggingface.co/Qwen/QwQ-32B-Preview\", \"Class\": \"LM-O\"},\n",
    "    \"qwen_prm7b\": {\"Name\": \"Qwen2.5-Math-PRM-7B\", \"Source\": \"https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B\", \"Class\": \"PRM\"},\n",
    "    \"qwen_prm72b\": {\"Name\": \"Qwen2.5-Math-PRM-72B\", \"Source\": \"https://huggingface.co/Qwen/Qwen2.5-Math-PRM-72B\", \"Class\": \"PRM\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_table(model_dict, classification_dict, res_dict):\n",
    "    res_str = \"\"\n",
    "    html_str = '<table class=\"js-sort-table\" id=\"results\">\\n'\n",
    "    \n",
    "    # Ë°®Â§¥ÈÉ®ÂàÜ\n",
    "    html_str += '  <tr>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>#</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Model</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Class</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Source</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Overall</strong></td>\\n'\n",
    "    \n",
    "    # Âä®ÊÄÅÁîüÊàêÂàÜÁ±ªÂàóÊ†áÈ¢ò\n",
    "    for big_classification_idx, (big_classification, current_classification_dict) in enumerate(classification_dict.items()):\n",
    "        for classification, display_classification_name in current_classification_dict.items():\n",
    "            html_str += f'    <td class=\"js-sort-number\"><strong>{display_classification_name}</strong></td>\\n'\n",
    "        html_str += f'    <td class=\"js-sort-number\"><strong>S{big_classification_idx+1}</strong></td>\\n'  # Ê∑ªÂä†Â§ßÁ±ª Avg Âàó\n",
    "    html_str += '  </tr>\\n'\n",
    "    res_str += html_str\n",
    "    sort_list = []\n",
    "    # Êï∞ÊçÆÈÉ®ÂàÜ\n",
    "    for idx, (model_k, model) in enumerate(model_dict.items()):\n",
    "        \n",
    "\n",
    "        # ËÆ°ÁÆó PRM Score\n",
    "        all_model_scores = sorted([get_prmscore_from_current_res_dict(res) for res in res_dict.values()], reverse=True)\n",
    "        current_res_dict = res_dict.get(model_k, {})\n",
    "        prm_score = get_prmscore_from_current_res_dict(current_res_dict)\n",
    "        if prm_score == all_model_scores[0]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•á</b></td>\\n'\n",
    "        elif prm_score == all_model_scores[1]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•à</b></td>\\n'\n",
    "        elif prm_score == all_model_scores[2]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•â</b></td>\\n'\n",
    "        else:\n",
    "            current_total_res_str= f'    <td><b class=\"\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"\">{model[\"Name\"]}</b></td>\\n'\n",
    "        html_str = ''\n",
    "        html_str += '  <tr>\\n'\n",
    "        html_str += \"    <td>{CURRENT_RANK}</td>\\n\"\n",
    "        html_str += current_model_name_str\n",
    "        html_str += f'    <td>{model[\"Class\"]}</td>\\n'\n",
    "        html_str += f'    <td><a href=\"{model[\"Source\"]}\" class=\"ext-link\" target=\"_blank\">Link</a></td>\\n'\n",
    "        html_str += current_total_res_str\n",
    "        currunt_total_prm_score = prm_score\n",
    "        # ÂàÜÁ±ªÊåáÊ†áÈÉ®ÂàÜ\n",
    "        for big_classification, current_classification_dict in classification_dict.items():\n",
    "            avg = []  # ‰øùÂ≠òÂΩìÂâçÂ§ßÁ±ªÁöÑÂàÜÁ±ªÊåáÊ†áÂàÜÊï∞\n",
    "            for classification, display_classification_name in current_classification_dict.items():\n",
    "                prm_score = get_prmscore_from_current_res_dict(current_res_dict, classification)\n",
    "                avg.append(prm_score)\n",
    "                html_str += f'    <td>{prm_score * 100:.1f}</td>\\n'\n",
    "            \n",
    "            #Â§ßÁ±ªÂπ≥ÂùáÂÄº\n",
    "            avg_score = sum(avg) / len(avg) if avg else 0\n",
    "            html_str += f'    <td><b class=\"\">{avg_score * 100:.1f}</b></td>\\n'\n",
    "\n",
    "        html_str += '  </tr>\\n'\n",
    "        sort_list.append((currunt_total_prm_score, html_str))\n",
    "    sort_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    for idx,(_, html_str) in enumerate(sort_list):\n",
    "        res_str += html_str.format(CURRENT_RANK=idx+1)\n",
    "    res_str += '</table>\\n'\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"js-sort-table\" id=\"results\">\n",
      "  <tr>\n",
      "    <td class=\"js-sort-number\"><strong>#</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Model</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Class</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Source</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Overall</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>NR.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>NCL.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S1</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>ES.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>SC.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>DC.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>CI.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S2</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>PS.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>DR.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>MS.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S3</strong></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>1</td>\n",
      "     <td><b class=\"best-score-text\">Gemini-2.0-thinking-exp-1219 ü•á</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://ai.google.dev/gemini-api/docs/thinking-mode\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">68.8</b></td>\n",
      "    <td>68.5</td>\n",
      "    <td>63.8</td>\n",
      "    <td><b class=\"\">66.2</b></td>\n",
      "    <td>72.9</td>\n",
      "    <td>71.3</td>\n",
      "    <td>71.0</td>\n",
      "    <td>71.8</td>\n",
      "    <td><b class=\"\">71.8</b></td>\n",
      "    <td>60.3</td>\n",
      "    <td>65.7</td>\n",
      "    <td>99.8</td>\n",
      "    <td><b class=\"\">75.3</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>2</td>\n",
      "     <td><b class=\"best-score-text\">o1-mini ü•à</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">68.8</b></td>\n",
      "    <td>65.6</td>\n",
      "    <td>63.7</td>\n",
      "    <td><b class=\"\">64.6</b></td>\n",
      "    <td>74.5</td>\n",
      "    <td>67.7</td>\n",
      "    <td>73.8</td>\n",
      "    <td>72.3</td>\n",
      "    <td><b class=\"\">72.1</b></td>\n",
      "    <td>61.8</td>\n",
      "    <td>64.8</td>\n",
      "    <td>100.0</td>\n",
      "    <td><b class=\"\">75.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>3</td>\n",
      "     <td><b class=\"best-score-text\">Qwen2.5-Math-PRM-72B ü•â</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Qwen/Qwen2.5-Math-PRM-72B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">68.2</b></td>\n",
      "    <td>50.4</td>\n",
      "    <td>58.8</td>\n",
      "    <td><b class=\"\">54.6</b></td>\n",
      "    <td>73.7</td>\n",
      "    <td>71.1</td>\n",
      "    <td>72.2</td>\n",
      "    <td>78.6</td>\n",
      "    <td><b class=\"\">73.9</b></td>\n",
      "    <td>60.3</td>\n",
      "    <td>71.2</td>\n",
      "    <td>99.4</td>\n",
      "    <td><b class=\"\">77.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>4</td>\n",
      "     <td><b class=\"\">GPT-4o</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://openai.com/index/hello-gpt-4o/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">66.8</b></td>\n",
      "    <td>57.0</td>\n",
      "    <td>62.4</td>\n",
      "    <td><b class=\"\">59.7</b></td>\n",
      "    <td>72.0</td>\n",
      "    <td>69.7</td>\n",
      "    <td>70.7</td>\n",
      "    <td>71.1</td>\n",
      "    <td><b class=\"\">70.9</b></td>\n",
      "    <td>62.5</td>\n",
      "    <td>65.7</td>\n",
      "    <td>99.2</td>\n",
      "    <td><b class=\"\">75.8</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>5</td>\n",
      "     <td><b class=\"\">Gemini-2.0-flash-exp</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://deepmind.google/technologies/gemini/flash/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "    <td>67.2</td>\n",
      "    <td>58.1</td>\n",
      "    <td><b class=\"\">62.7</b></td>\n",
      "    <td>70.4</td>\n",
      "    <td>65.7</td>\n",
      "    <td>66.0</td>\n",
      "    <td>67.3</td>\n",
      "    <td><b class=\"\">67.3</b></td>\n",
      "    <td>61.8</td>\n",
      "    <td>66.2</td>\n",
      "    <td>98.2</td>\n",
      "    <td><b class=\"\">75.4</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>6</td>\n",
      "     <td><b class=\"\">Qwen2.5-Math-PRM-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">65.5</b></td>\n",
      "    <td>49.0</td>\n",
      "    <td>55.1</td>\n",
      "    <td><b class=\"\">52.1</b></td>\n",
      "    <td>71.8</td>\n",
      "    <td>67.3</td>\n",
      "    <td>66.3</td>\n",
      "    <td>78.5</td>\n",
      "    <td><b class=\"\">71.0</b></td>\n",
      "    <td>57.6</td>\n",
      "    <td>69.1</td>\n",
      "    <td>99.7</td>\n",
      "    <td><b class=\"\">75.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>7</td>\n",
      "     <td><b class=\"\">QwQ-Preview-32B</b></td>\n",
      "    <td>LM-O</td>\n",
      "    <td><a href=\"https://huggingface.co/Qwen/QwQ-32B-Preview\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">63.6</b></td>\n",
      "    <td>57.2</td>\n",
      "    <td>55.6</td>\n",
      "    <td><b class=\"\">56.4</b></td>\n",
      "    <td>67.4</td>\n",
      "    <td>72.3</td>\n",
      "    <td>66.2</td>\n",
      "    <td>66.9</td>\n",
      "    <td><b class=\"\">68.2</b></td>\n",
      "    <td>57.8</td>\n",
      "    <td>62.7</td>\n",
      "    <td>100.0</td>\n",
      "    <td><b class=\"\">73.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>8</td>\n",
      "     <td><b class=\"\">ReasonEval-34B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/GAIR/ReasonEval-34B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">60.5</b></td>\n",
      "    <td>54.8</td>\n",
      "    <td>48.1</td>\n",
      "    <td><b class=\"\">51.5</b></td>\n",
      "    <td>66.4</td>\n",
      "    <td>60.3</td>\n",
      "    <td>57.8</td>\n",
      "    <td>67.5</td>\n",
      "    <td><b class=\"\">63.0</b></td>\n",
      "    <td>57.7</td>\n",
      "    <td>64.3</td>\n",
      "    <td>97.2</td>\n",
      "    <td><b class=\"\">73.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>9</td>\n",
      "     <td><b class=\"\">ReasonEval-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/GAIR/ReasonEval-7B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">60.1</b></td>\n",
      "    <td>61.0</td>\n",
      "    <td>50.1</td>\n",
      "    <td><b class=\"\">55.6</b></td>\n",
      "    <td>62.1</td>\n",
      "    <td>65.9</td>\n",
      "    <td>61.5</td>\n",
      "    <td>66.0</td>\n",
      "    <td><b class=\"\">63.9</b></td>\n",
      "    <td>55.7</td>\n",
      "    <td>58.0</td>\n",
      "    <td>99.5</td>\n",
      "    <td><b class=\"\">71.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>10</td>\n",
      "     <td><b class=\"\">RLHFlow-PRM-Mistral-8B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.4</b></td>\n",
      "    <td>46.1</td>\n",
      "    <td>47.3</td>\n",
      "    <td><b class=\"\">46.7</b></td>\n",
      "    <td>56.6</td>\n",
      "    <td>55.1</td>\n",
      "    <td>54.4</td>\n",
      "    <td>63.8</td>\n",
      "    <td><b class=\"\">57.5</b></td>\n",
      "    <td>51.5</td>\n",
      "    <td>56.2</td>\n",
      "    <td>97.9</td>\n",
      "    <td><b class=\"\">68.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>11</td>\n",
      "     <td><b class=\"\">RLHFlow-PRM-Deepseek-8B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.2</b></td>\n",
      "    <td>46.4</td>\n",
      "    <td>48.9</td>\n",
      "    <td><b class=\"\">47.6</b></td>\n",
      "    <td>55.7</td>\n",
      "    <td>55.0</td>\n",
      "    <td>53.2</td>\n",
      "    <td>66.2</td>\n",
      "    <td><b class=\"\">57.5</b></td>\n",
      "    <td>49.0</td>\n",
      "    <td>55.4</td>\n",
      "    <td>99.8</td>\n",
      "    <td><b class=\"\">68.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>12</td>\n",
      "     <td><b class=\"\">MATHMinos-Mistral-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://github.com/KbsdJames/MATH-Minos\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.2</b></td>\n",
      "    <td>48.8</td>\n",
      "    <td>54.0</td>\n",
      "    <td><b class=\"\">51.4</b></td>\n",
      "    <td>57.0</td>\n",
      "    <td>52.1</td>\n",
      "    <td>50.7</td>\n",
      "    <td>57.8</td>\n",
      "    <td><b class=\"\">54.4</b></td>\n",
      "    <td>52.8</td>\n",
      "    <td>55.8</td>\n",
      "    <td>91.1</td>\n",
      "    <td><b class=\"\">66.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>13</td>\n",
      "     <td><b class=\"\">Llemma-PRM800k-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">52.0</b></td>\n",
      "    <td>49.3</td>\n",
      "    <td>53.4</td>\n",
      "    <td><b class=\"\">51.4</b></td>\n",
      "    <td>56.4</td>\n",
      "    <td>47.1</td>\n",
      "    <td>46.7</td>\n",
      "    <td>53.3</td>\n",
      "    <td><b class=\"\">50.9</b></td>\n",
      "    <td>51.0</td>\n",
      "    <td>53.5</td>\n",
      "    <td>93.6</td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>14</td>\n",
      "     <td><b class=\"\">Llemma-MetaMath-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">50.5</b></td>\n",
      "    <td>50.2</td>\n",
      "    <td>50.5</td>\n",
      "    <td><b class=\"\">50.3</b></td>\n",
      "    <td>51.9</td>\n",
      "    <td>47.6</td>\n",
      "    <td>44.4</td>\n",
      "    <td>52.1</td>\n",
      "    <td><b class=\"\">49.0</b></td>\n",
      "    <td>50.5</td>\n",
      "    <td>51.3</td>\n",
      "    <td>96.0</td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>15</td>\n",
      "     <td><b class=\"\">Llemma-oprm-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">50.3</b></td>\n",
      "    <td>48.7</td>\n",
      "    <td>49.3</td>\n",
      "    <td><b class=\"\">49.0</b></td>\n",
      "    <td>54.2</td>\n",
      "    <td>46.8</td>\n",
      "    <td>44.5</td>\n",
      "    <td>53.5</td>\n",
      "    <td><b class=\"\">49.8</b></td>\n",
      "    <td>49.2</td>\n",
      "    <td>51.3</td>\n",
      "    <td>91.8</td>\n",
      "    <td><b class=\"\">64.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>16</td>\n",
      "     <td><b class=\"\">MathShepherd-Mistral-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">47.0</b></td>\n",
      "    <td>44.0</td>\n",
      "    <td>50.3</td>\n",
      "    <td><b class=\"\">47.1</b></td>\n",
      "    <td>49.4</td>\n",
      "    <td>44.5</td>\n",
      "    <td>41.3</td>\n",
      "    <td>47.7</td>\n",
      "    <td><b class=\"\">45.7</b></td>\n",
      "    <td>47.2</td>\n",
      "    <td>48.6</td>\n",
      "    <td>86.1</td>\n",
      "    <td><b class=\"\">60.7</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>17</td>\n",
      "     <td><b class=\"\">Skywork-PRM-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">36.2</b></td>\n",
      "    <td>35.7</td>\n",
      "    <td>41.2</td>\n",
      "    <td><b class=\"\">38.4</b></td>\n",
      "    <td>36.7</td>\n",
      "    <td>29.1</td>\n",
      "    <td>30.6</td>\n",
      "    <td>34.4</td>\n",
      "    <td><b class=\"\">32.7</b></td>\n",
      "    <td>36.8</td>\n",
      "    <td>37.4</td>\n",
      "    <td>88.8</td>\n",
      "    <td><b class=\"\">54.3</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>18</td>\n",
      "     <td><b class=\"\">Skywork-PRM-1.5B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">31.5</b></td>\n",
      "    <td>31.2</td>\n",
      "    <td>35.6</td>\n",
      "    <td><b class=\"\">33.4</b></td>\n",
      "    <td>32.3</td>\n",
      "    <td>25.6</td>\n",
      "    <td>25.7</td>\n",
      "    <td>29.9</td>\n",
      "    <td><b class=\"\">28.4</b></td>\n",
      "    <td>32.8</td>\n",
      "    <td>32.0</td>\n",
      "    <td>80.9</td>\n",
      "    <td><b class=\"\">48.6</b></td>\n",
      "  </tr>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "\n",
    "## PRMs\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(prm_model_dict.keys()))\n",
    "prm_str = get_html_table(prm_model_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += prm_str\n",
    "\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
