{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mr_eval.utils.utils import *\n",
    "import os\n",
    "\n",
    "def list_jsonl_files(folder_path):\n",
    "    \"\"\"\n",
    "    Âàó‰∏æÊñá‰ª∂Â§π‰∏≠ÁöÑÊâÄÊúâ .jsonl Êñá‰ª∂\n",
    "    Args:\n",
    "        folder_path (str): Êñá‰ª∂Â§πË∑ØÂæÑ\n",
    "    Returns:\n",
    "        List[str]: ÊâÄÊúâ .jsonl Êñá‰ª∂ÁöÑË∑ØÂæÑ\n",
    "    \"\"\"\n",
    "    return [f for f in os.listdir(folder_path) if f.endswith(\".jsonl\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model names\n",
    "prm_model_name_dict = dict(\n",
    "    skyworkprm_1_5B=\"\\\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B}{Skywork-PRM-1.5B}\",\n",
    "    skyworkprm_7B=\"\\\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B}{Skywork-PRM-7B}\",\n",
    "    llemma7b_prm_prm800k=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf}{Llemma-PRM800k-7B}\",\n",
    "    llemma7b_prm_metamath=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf}{Llemma-MetaMath-7B}\",\n",
    "    llemma7b_oprm_prm800k=\"\\\\href{https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf}{Llemma-oprm-7B}\",\n",
    "    mathminos_mistral=\"\\\\href{https://github.com/KbsdJames/MATH-Minos}{MATHMinos-Mistral-7B}\",\n",
    "    mathshepherd=\"\\\\href{https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm}{MathShepherd-Mistral-7B}\",\n",
    "    reasoneval7b=\"\\\\href{https://huggingface.co/GAIR/ReasonEval-7B}{ReasonEval-7B}\",\n",
    "    llama3_1_8b_prm_mistral=\"\\\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data}{RLHFlow-PRM-Mistral-8B}\",\n",
    "    llama3_1_8b_prm_deepseek=\"\\\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data}{RLHFlow-PRM-Deepseek-8B}\",\n",
    "    reasoneval34b=\"\\\\href{https://huggingface.co/GAIR/ReasonEval-34B}{ReasonEval-34B}\",\n",
    ")\n",
    "close_model_name_dict = dict(\n",
    "    gpt4o=\"\\\\href{https://openai.com/index/hello-gpt-4o/}{GPT-4o}\",\n",
    "    o1mini=\"\\\\href{https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/}{o1-mini}$^\\dagger$\",\n",
    "    \n",
    "    gemini_2_flash=\"\\\\href{https://deepmind.google/technologies/gemini/flash/}{Gemini-2.0-flash-exp}\",\n",
    "    gemini_2_thinking=\"\\\\href{https://ai.google.dev/gemini-api/docs/thinking-mode}{Gemini-2.0-thinking-exp-1219}\",\n",
    ")\n",
    "    \n",
    "open_model_name_dict = dict(\n",
    "    o1preview=\"\\\\href{https://openai.com/index/introducing-openai-o1-preview/}{o1-preview}$^\\dagger$\",\n",
    "    qwen_qwq=\"\\\\href{https://huggingface.co/Qwen/QwQ-32B-Preview}{QwQ-Preview-32B}\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "classification_name_dict = dict(\n",
    "    domain_inconsistency=\"DC.\",\n",
    "    redundency=\"NR.\",\n",
    "    multi_solutions=\"MS.\",\n",
    "    deception=\"DR.\",\n",
    "    confidence=\"CI.\",\n",
    "    step_contradiction=\"SC.\",\n",
    "    circular=\"NCL.\",\n",
    "    missing_condition=\"PS.\",\n",
    "    counterfactual=\"ES.\"\n",
    ")\n",
    "classification_parallel_dict = dict(\n",
    "    simplicity=dict(\n",
    "        redundency=\"NR.\",\n",
    "        circular=\"NCL.\",\n",
    "    ),\n",
    "    soundness=dict(\n",
    "        counterfactual=\"ES.\",\n",
    "        step_contradiction=\"SC.\",\n",
    "        domain_inconsistency=\"DC.\",\n",
    "        confidence=\"CI.\",\n",
    "    ),\n",
    "    sensitivity=dict(\n",
    "        missing_condition=\"PS.\",\n",
    "        deception=\"DR.\",\n",
    "        multi_solutions=\"MS.\",\n",
    "    )\n",
    ")\n",
    "classifications = [\"redundency\", \"circular\", \"counterfactual\", \"step_contradiction\", \"domain_inconsistency\",  \"confidence\", \"missing_condition\", \"deception\", \"multi_solutions\", ]\n",
    "metrics = [\"f1\", \"negative_f1\", \"total_step_acc\", \"correct_step_acc\", \"wrong_step_acc\", \"first_error_acc\", \"similarity\",]\n",
    "\n",
    "## File paths\n",
    "res_dir = \"/mnt/petrelfs/songmingyang/code/reasoning/MR_Hallucination/mr_eval/scripts/logs/prmtest_classified\"\n",
    "res_files = list_jsonl_files(res_dir)\n",
    "res_names = [f.split(\".\")[0] for f in res_files]\n",
    "res_paths = [os.path.join(res_dir, f) for f in res_files]\n",
    "file_dict = dict(zip(res_names, res_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_dict(file_dict,model_lists=None):\n",
    "    res_dict = {}\n",
    "    if not model_lists:\n",
    "        for model_name, file_path in file_dict.items():\n",
    "            res_dict[model_name] = process_jsonl(file_path)[-1]\n",
    "    else:\n",
    "        for model_name in model_lists:\n",
    "            file_path = file_dict[model_name]\n",
    "            res_dict[model_name] = process_jsonl(file_path)[-1]\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def get_prmscore_from_current_res_dict(res_dict,classification=None):\n",
    "    '''\n",
    "    Get PRM score from model level dict\n",
    "    '''\n",
    "    if not classification:\n",
    "        prm_score = res_dict[\"total_hallucination_results\"]['f1'] * 0.5 + res_dict[\"total_hallucination_results\"]['negative_f1'] * 0.5\n",
    "    else:\n",
    "        if classification in [\"multi_solutions\"]:\n",
    "            prm_score = res_dict[\"hallucination_type_results\"]['f1'][classification]\n",
    "        else:\n",
    "            prm_score = res_dict[\"hallucination_type_results\"]['f1'][classification] * 0.5 + res_dict[\"hallucination_type_results\"]['negative_f1'][classification] * 0.5\n",
    "    return prm_score\n",
    "\n",
    "\n",
    "def get_avg_prmscore_from_current_res_dict(res_dict,classifications):\n",
    "    '''\n",
    "    Get AVG PRM score from model level dict\n",
    "    '''\n",
    "    assert classifications\n",
    "    res = [get_prmscore_from_current_res_dict(res_dict,classification) for classification in classifications]\n",
    "    return sum(res) / len(res)\n",
    "    \n",
    "\n",
    "def get_res_str(model_dict,classification_dict,res_dict):\n",
    "    res_str = \"\"\n",
    "    # current_classification_dict = classification_dict[classification_name]\n",
    "    avg_res_list = []\n",
    "    for idx,(model_name, model_display_name) in enumerate(model_dict.items()):\n",
    "        temp_str = f\"{model_display_name}\"\n",
    "        current_res_dict = res_dict[model_name]\n",
    "        prm_score = get_prmscore_from_current_res_dict(current_res_dict)\n",
    "        all_model_scores = sorted([get_prmscore_from_current_res_dict(res) for res in res_dict.values()],reverse=True)\n",
    "        if idx == 0:\n",
    "            avg_res_list.append(sum(all_model_scores) / len(all_model_scores))\n",
    "        if prm_score == max(all_model_scores):\n",
    "            temp_str += f\" & \\\\textbf{{{prm_score * 100:.1f}}}\"\n",
    "        elif prm_score == all_model_scores[1]:\n",
    "            temp_str += f\" & \\\\underline{{{prm_score * 100:.1f}}}\"\n",
    "        else:\n",
    "            temp_str += f\" & {prm_score * 100:.1f}\"\n",
    "        \n",
    "        for big_classification, current_classification_dict in classification_dict.items():\n",
    "            all_avt = sorted([get_avg_prmscore_from_current_res_dict(res,list(current_classification_dict.keys())) for res in res_dict.values()], reverse=True)\n",
    "            avg = []\n",
    "            for classification, display_classification_name in current_classification_dict.items():\n",
    "                prm_score = get_prmscore_from_current_res_dict(current_res_dict,classification)\n",
    "                all_prm_scores = sorted([get_prmscore_from_current_res_dict(res,classification) for res in res_dict.values()], reverse=True)\n",
    "                if idx == 0:\n",
    "                    avg_res_list.append(sum(all_prm_scores) / len(all_prm_scores))\n",
    "                avg.append(prm_score)\n",
    "                if prm_score == max(all_prm_scores):\n",
    "                    temp_str += f\" & \\\\textbf{{{prm_score * 100:.1f}}}\"\n",
    "                elif prm_score == all_prm_scores[1]:\n",
    "                    temp_str += f\" & \\\\underline{{{prm_score * 100:.1f}}}\"\n",
    "                else:\n",
    "                    temp_str += f\" & {prm_score * 100:.1f}\"\n",
    "            avg_score = sum(avg) / len(avg)\n",
    "            if avg_score == max(all_avt):\n",
    "                temp_str += f\" & \\\\textbf{{{avg_score * 100:.1f}}}\"\n",
    "            elif avg_score == all_avt[1]:\n",
    "                temp_str += f\" & \\\\underline{{{avg_score * 100:.1f}}}\"\n",
    "            else:\n",
    "                temp_str += f\" & {avg_score * 100:.1f}\"\n",
    "            if idx == 0:\n",
    "                avg_res_list.append(sum(all_avt) / len(all_avt))\n",
    "        temp_str += \"\\\\\\\\\\n\"\n",
    "        res_str += temp_str\n",
    "    avg_res_str = \"\\\\cellcolor{gray!10} \\\\textbf{Avg.} \"\n",
    "    for res in avg_res_list:\n",
    "        avg_res_str += f\"& \\\\cellcolor{{gray!10}} {res * 100:.1f} \"\n",
    "    avg_res_str += \"\\\\\\\\\\n\"\n",
    "    res_str += avg_res_str\n",
    "    \n",
    "    return res_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\hline \\multicolumn{14}{c}{\\textit{\\textbf{Open-source Process Level Reward Models}}} \\\\   \\hline \n",
      "\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B}{Skywork-PRM-1.5B} & 31.7 & 31.4 & 35.8 & 33.6 & 32.4 & 25.7 & 26.0 & 30.2 & 28.6 & 33.1 & 32.3 & 81.1 & 48.8\\\\\n",
      "\\href{https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B}{Skywork-PRM-7B} & 36.2 & 35.7 & 41.2 & 38.4 & 36.7 & 29.1 & 30.6 & 34.4 & 32.7 & 36.8 & 37.4 & 88.8 & 54.3\\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf}{Llemma-PRM800k-7B} & 52.0 & 49.3 & \\underline{53.4} & 51.4 & 56.4 & 47.1 & 46.7 & 53.3 & 50.9 & 51.0 & 53.5 & 93.6 & 66.0\\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf}{Llemma-MetaMath-7B} & 50.5 & 50.2 & 50.5 & 50.3 & 51.9 & 47.6 & 44.4 & 52.1 & 49.0 & 50.5 & 51.3 & 96.0 & 66.0\\\\\n",
      "\\href{https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf}{Llemma-oprm-7B} & 50.3 & 48.7 & 49.3 & 49.0 & 54.2 & 46.8 & 44.5 & 53.5 & 49.8 & 49.2 & 51.3 & 91.8 & 64.1\\\\\n",
      "\\href{https://github.com/KbsdJames/MATH-Minos}{MATHMinos-Mistral-7B} & 54.2 & 48.8 & \\textbf{54.0} & 51.4 & 57.0 & 52.1 & 50.7 & 57.8 & 54.4 & 52.8 & 55.8 & 91.1 & 66.5\\\\\n",
      "\\href{https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm}{MathShepherd-Mistral-7B} & 47.0 & 44.0 & 50.3 & 47.1 & 49.4 & 44.5 & 41.3 & 47.7 & 45.7 & 47.2 & 48.6 & 86.1 & 60.7\\\\\n",
      "\\href{https://huggingface.co/GAIR/ReasonEval-7B}{ReasonEval-7B} & \\underline{60.0} & \\textbf{61.0} & 50.1 & \\textbf{55.6} & \\underline{62.1} & \\textbf{65.9} & \\textbf{61.5} & 65.9 & \\textbf{63.8} & \\underline{55.6} & \\underline{57.9} & \\underline{99.5} & \\underline{71.0}\\\\\n",
      "\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data}{RLHFlow-PRM-Mistral-8B} & 54.4 & 46.1 & 47.3 & 46.7 & 56.6 & 55.1 & 54.4 & 63.8 & 57.5 & 51.5 & 56.2 & 97.9 & 68.5\\\\\n",
      "\\href{https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data}{RLHFlow-PRM-Deepseek-8B} & 54.2 & 46.4 & 48.9 & 47.6 & 55.7 & 55.0 & 53.2 & \\underline{66.2} & 57.5 & 49.0 & 55.4 & \\textbf{99.8} & 68.1\\\\\n",
      "\\href{https://huggingface.co/GAIR/ReasonEval-34B}{ReasonEval-34B} & \\textbf{60.5} & \\underline{54.8} & 48.1 & \\underline{51.5} & \\textbf{66.4} & \\underline{60.3} & \\underline{57.8} & \\textbf{67.5} & \\underline{63.0} & \\textbf{57.7} & \\textbf{64.3} & 97.2 & \\textbf{73.1}\\\\\n",
      "\\cellcolor{gray!10} \\textbf{Avg.} & \\cellcolor{gray!10} 50.1 & \\cellcolor{gray!10} 47.0 & \\cellcolor{gray!10} 48.1 & \\cellcolor{gray!10} 47.5 & \\cellcolor{gray!10} 52.6 & \\cellcolor{gray!10} 48.1 & \\cellcolor{gray!10} 46.5 & \\cellcolor{gray!10} 53.9 & \\cellcolor{gray!10} 50.3 & \\cellcolor{gray!10} 48.6 & \\cellcolor{gray!10} 51.3 & \\cellcolor{gray!10} 93.0 & \\cellcolor{gray!10} 64.3 \\\\\n",
      "\\hline \\multicolumn{14}{c}{\\textit{\\textbf{Proprietary LLMs, Prompted as Critic Models}}} \\\\   \\hline \n",
      "\\href{https://openai.com/index/hello-gpt-4o/}{GPT-4o} & 66.8 & 57.0 & 62.4 & 59.7 & 72.0 & \\underline{69.7} & 70.7 & 71.1 & 70.9 & \\textbf{62.5} & 65.7 & 99.2 & \\textbf{75.8}\\\\\n",
      "\\href{https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/}{o1-mini}$^\\dagger$ & \\underline{68.8} & 65.6 & \\underline{63.7} & \\underline{64.6} & \\textbf{74.5} & 67.7 & \\textbf{73.8} & \\textbf{72.3} & \\textbf{72.1} & \\underline{61.8} & 64.8 & \\textbf{100.0} & \\underline{75.5}\\\\\n",
      "\\href{https://deepmind.google/technologies/gemini/flash/}{Gemini-2.0-flash-exp} & 66.0 & \\underline{67.2} & 58.1 & 62.7 & 70.4 & 65.7 & 66.0 & 67.3 & 67.3 & 61.8 & \\textbf{66.2} & 98.2 & 75.4\\\\\n",
      "\\href{https://ai.google.dev/gemini-api/docs/thinking-mode}{Gemini-2.0-thinking-exp-1219} & \\textbf{68.8} & \\textbf{68.5} & \\textbf{63.8} & \\textbf{66.2} & \\underline{72.9} & \\textbf{71.3} & \\underline{71.0} & \\underline{71.8} & \\underline{71.8} & 60.3 & \\underline{65.7} & \\underline{99.8} & 75.3\\\\\n",
      "\\cellcolor{gray!10} \\textbf{Avg.} & \\cellcolor{gray!10} 67.6 & \\cellcolor{gray!10} 64.6 & \\cellcolor{gray!10} 62.0 & \\cellcolor{gray!10} 63.3 & \\cellcolor{gray!10} 72.4 & \\cellcolor{gray!10} 68.6 & \\cellcolor{gray!10} 70.4 & \\cellcolor{gray!10} 70.7 & \\cellcolor{gray!10} 70.5 & \\cellcolor{gray!10} 61.6 & \\cellcolor{gray!10} 65.6 & \\cellcolor{gray!10} 99.3 & \\cellcolor{gray!10} 75.5 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "\n",
    "## PRMs\n",
    "model_type_panel=\"\\hline \\multicolumn{14}{c}{\\\\textit{\\\\textbf{Open-source Process Level Reward Models}}} \\\\\\\\   \\hline \\n\"\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(prm_model_name_dict.keys()))\n",
    "prm_str = get_res_str(prm_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += model_type_panel + prm_str\n",
    "\n",
    "## Close Models\n",
    "model_type_panel= \"\\hline \\multicolumn{14}{c}{\\\\textit{\\\\textbf{Proprietary LLMs, Prompted as Critic Models}}} \\\\\\\\   \\hline \\n\"\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(close_model_name_dict.keys()))\n",
    "close_str = get_res_str(close_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += model_type_panel + close_str\n",
    "\n",
    "\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model names\n",
    "prm_model_name_dict = dict(\n",
    "    skyworkprm_1_5B=\"[Skywork-PRM-1.5B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B)\",\n",
    "    skyworkprm_7B=\"[Skywork-PRM-7B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B)\",\n",
    "    llemma7b_prm_prm800k=\"[Llemma-PRM800k-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf)\",\n",
    "    llemma7b_prm_metamath=\"[Llemma-MetaMath-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf)\",\n",
    "    llemma7b_oprm_prm800k=\"[Llemma-oprm-7B](https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf)\",\n",
    "    mathminos_mistral=\"[MATHMinos-Mistral-7B](https://github.com/KbsdJames/MATH-Minos)\",\n",
    "    mathshepherd=\"[MathShepherd-Mistral-7B](https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm)\",\n",
    "    reasoneval7b=\"[ReasonEval-7B](https://huggingface.co/GAIR/ReasonEval-7B)\",\n",
    "    llama3_1_8b_prm_mistral=\"[RLHFlow-PRM-Mistral-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data)\",\n",
    "    llama3_1_8b_prm_deepseek=\"[RLHFlow-PRM-Deepseek-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data)\",\n",
    "    reasoneval34b=\"[ReasonEval-34B](https://huggingface.co/GAIR/ReasonEval-34B)\",\n",
    "    qwen_prm7b=\"[Qwen2.5-Math-PRM-7B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B)\",\n",
    ")\n",
    "\n",
    "close_model_name_dict = dict(\n",
    "    gpt4o=\"[GPT-4o](https://openai.com/index/hello-gpt-4o/)\",\n",
    "    o1mini=\"[o1-mini](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)\\\\$^\\dagger$\",\n",
    "    \n",
    "    gemini_2_flash=\"[Gemini-2.0-flash-exp](https://deepmind.google/technologies/gemini/flash/)\",\n",
    "    gemini_2_thinking=\"[Gemini-2.0-thinking-exp-1219](https://ai.google.dev/gemini-api/docs/thinking-mode)\",\n",
    ")\n",
    "\n",
    "open_model_name_dict = dict(\n",
    "    o1preview=\"[o1-preview](https://openai.com/index/introducing-openai-o1-preview/)\\\\$^\\dagger$\",\n",
    "    qwen_qwq=\"[QwQ-Preview-32B](https://huggingface.co/Qwen/QwQ-32B-Preview)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_res_str(model_dict, classification_dict, res_dict):\n",
    "    res_str = \"\"\n",
    "    avg_res_list = []\n",
    "\n",
    "    # Ë°®Â§¥ÈÉ®ÂàÜ\n",
    "    header_row = \"| Model | Overall\"\n",
    "    separator_row = \"|-------|-------\"\n",
    "    for big_classification, current_classification_dict in classification_dict.items():\n",
    "        for classification, display_classification_name in current_classification_dict.items():\n",
    "            header_row += f\"| {display_classification_name} \"\n",
    "            separator_row += \"|-------\"\n",
    "        header_row += f\"| Avg ({big_classification}) \"\n",
    "        separator_row += \"|-------\"\n",
    "    header_row += \" |\\n\"\n",
    "    separator_row += \" |\\n\"\n",
    "    res_str += header_row + separator_row\n",
    "\n",
    "    # Êï∞ÊçÆÈÉ®ÂàÜ\n",
    "    for idx, (model_name, model_display_name) in enumerate(model_dict.items()):\n",
    "        temp_str = f\"| {model_display_name} \"\n",
    "        current_res_dict = res_dict[model_name]\n",
    "\n",
    "        # ËÆ°ÁÆó PRM Score\n",
    "        prm_score = get_prmscore_from_current_res_dict(current_res_dict)\n",
    "        all_model_scores = sorted([get_prmscore_from_current_res_dict(res) for res in res_dict.values()], reverse=True)\n",
    "        if idx == 0:\n",
    "            avg_res_list.append(sum(all_model_scores) / len(all_model_scores))\n",
    "        if prm_score == max(all_model_scores):\n",
    "            temp_str += f\"| **{prm_score * 100:.1f}** \"\n",
    "        elif prm_score == all_model_scores[1]:\n",
    "            temp_str += f\"| _{prm_score * 100:.1f}_ \"\n",
    "        else:\n",
    "            temp_str += f\"| {prm_score * 100:.1f} \"\n",
    "\n",
    "        # ÂàÜÁ±ªÊåáÊ†áÈÉ®ÂàÜ\n",
    "        for big_classification, current_classification_dict in classification_dict.items():\n",
    "            all_avt = sorted([get_avg_prmscore_from_current_res_dict(res, list(current_classification_dict.keys())) for res in res_dict.values()], reverse=True)\n",
    "            avg = []\n",
    "            for classification, display_classification_name in current_classification_dict.items():\n",
    "                prm_score = get_prmscore_from_current_res_dict(current_res_dict, classification)\n",
    "                all_prm_scores = sorted([get_prmscore_from_current_res_dict(res, classification) for res in res_dict.values()], reverse=True)\n",
    "                if idx == 0:\n",
    "                    avg_res_list.append(sum(all_prm_scores) / len(all_prm_scores))\n",
    "                avg.append(prm_score)\n",
    "                if prm_score == max(all_prm_scores):\n",
    "                    temp_str += f\"| **{prm_score * 100:.1f}** \"\n",
    "                elif prm_score == all_prm_scores[1]:\n",
    "                    temp_str += f\"| _{prm_score * 100:.1f}_ \"\n",
    "                else:\n",
    "                    temp_str += f\"| {prm_score * 100:.1f} \"\n",
    "\n",
    "            # ÂàÜÁ±ªÊåáÊ†áÁöÑÂπ≥ÂùáÂàÜ\n",
    "            avg_score = sum(avg) / len(avg)\n",
    "            if avg_score == max(all_avt):\n",
    "                temp_str += f\"| **{avg_score * 100:.1f}** \"\n",
    "            elif avg_score == all_avt[1]:\n",
    "                temp_str += f\"| _{avg_score * 100:.1f}_ \"\n",
    "            else:\n",
    "                temp_str += f\"| {avg_score * 100:.1f} \"\n",
    "            if idx == 0:\n",
    "                avg_res_list.append(sum(all_avt) / len(all_avt))\n",
    "\n",
    "        # Ë°åÁªìÊùü\n",
    "        temp_str += \"\\n\"\n",
    "        res_str += temp_str\n",
    "\n",
    "    # Âπ≥ÂùáË°å\n",
    "    avg_res_str = \"| **Avg.** \"\n",
    "    for res in avg_res_list:\n",
    "        avg_res_str += f\"| **{res * 100:.1f}** \"\n",
    "    avg_res_str += \"|\\n\"\n",
    "    res_str += avg_res_str\n",
    "\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model | Overall| NR. | NCL. | Avg (simplicity) | ES. | SC. | DC. | CI. | Avg (soundness) | PS. | DR. | MS. | Avg (sensitivity)  |\n",
      "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------- |\n",
      "| [Skywork-PRM-1.5B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B) | 31.7 | 31.4 | 35.8 | 33.6 | 32.4 | 25.7 | 26.0 | 30.2 | 28.6 | 33.1 | 32.3 | 81.1 | 48.8 \n",
      "| [Skywork-PRM-7B](https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B) | 36.2 | 35.7 | 41.2 | 38.4 | 36.7 | 29.1 | 30.6 | 34.4 | 32.7 | 36.8 | 37.4 | 88.8 | 54.3 \n",
      "| [Llemma-PRM800k-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf) | 52.0 | 49.3 | 53.4 | 51.4 | 56.4 | 47.1 | 46.7 | 53.3 | 50.9 | 51.0 | 53.5 | 93.6 | 66.0 \n",
      "| [Llemma-MetaMath-7B](https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf) | 50.5 | 50.2 | 50.5 | 50.3 | 51.9 | 47.6 | 44.4 | 52.1 | 49.0 | 50.5 | 51.3 | 96.0 | 66.0 \n",
      "| [Llemma-oprm-7B](https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf) | 50.3 | 48.7 | 49.3 | 49.0 | 54.2 | 46.8 | 44.5 | 53.5 | 49.8 | 49.2 | 51.3 | 91.8 | 64.1 \n",
      "| [MATHMinos-Mistral-7B](https://github.com/KbsdJames/MATH-Minos) | 54.2 | 48.8 | _54.0_ | 51.4 | 57.0 | 52.1 | 50.7 | 57.8 | 54.4 | 52.8 | 55.8 | 91.1 | 66.5 \n",
      "| [MathShepherd-Mistral-7B](https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm) | 47.0 | 44.0 | 50.3 | 47.1 | 49.4 | 44.5 | 41.3 | 47.7 | 45.7 | 47.2 | 48.6 | 86.1 | 60.7 \n",
      "| [ReasonEval-7B](https://huggingface.co/GAIR/ReasonEval-7B) | 60.0 | **61.0** | 50.1 | **55.6** | 62.1 | _65.9_ | _61.5_ | 65.9 | _63.8_ | 55.6 | 57.9 | 99.5 | 71.0 \n",
      "| [RLHFlow-PRM-Mistral-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data) | 54.4 | 46.1 | 47.3 | 46.7 | 56.6 | 55.1 | 54.4 | 63.8 | 57.5 | 51.5 | 56.2 | 97.9 | 68.5 \n",
      "| [RLHFlow-PRM-Deepseek-8B](https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data) | 54.2 | 46.4 | 48.9 | 47.6 | 55.7 | 55.0 | 53.2 | 66.2 | 57.5 | 49.0 | 55.4 | **99.8** | 68.1 \n",
      "| [ReasonEval-34B](https://huggingface.co/GAIR/ReasonEval-34B) | _60.5_ | _54.8_ | 48.1 | 51.5 | _66.4_ | 60.3 | 57.8 | _67.5_ | 63.0 | **57.7** | _64.3_ | 97.2 | _73.1_ \n",
      "| [Qwen2.5-Math-PRM-7B](https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B) | **65.5** | 49.1 | **55.2** | _52.1_ | **71.8** | **67.2** | **66.3** | **78.5** | **71.0** | _57.7_ | **69.2** | _99.7_ | **75.6** \n",
      "| **Avg.** | **51.4** | **47.1** | **48.7** | **47.9** | **54.2** | **49.7** | **48.1** | **55.9** | **52.0** | **49.3** | **52.8** | **93.6** | **65.2** |\n",
      "| Model | Overall| NR. | NCL. | Avg (simplicity) | ES. | SC. | DC. | CI. | Avg (soundness) | PS. | DR. | MS. | Avg (sensitivity)  |\n",
      "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|------- |\n",
      "| [GPT-4o](https://openai.com/index/hello-gpt-4o/) | 66.8 | 57.0 | 62.4 | 59.7 | 72.0 | _69.7_ | 70.7 | 71.1 | 70.9 | **62.5** | 65.7 | 99.2 | **75.8** \n",
      "| [o1-mini](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)\\$^\\dagger$ | _68.8_ | 65.6 | _63.7_ | _64.6_ | **74.5** | 67.7 | **73.8** | **72.3** | **72.1** | _61.8_ | 64.8 | **100.0** | _75.5_ \n",
      "| [Gemini-2.0-flash-exp](https://deepmind.google/technologies/gemini/flash/) | 66.0 | _67.2_ | 58.1 | 62.7 | 70.4 | 65.7 | 66.0 | 67.3 | 67.3 | 61.8 | **66.2** | 98.2 | 75.4 \n",
      "| [Gemini-2.0-thinking-exp-1219](https://ai.google.dev/gemini-api/docs/thinking-mode) | **68.8** | **68.5** | **63.8** | **66.2** | _72.9_ | **71.3** | _71.0_ | _71.8_ | _71.8_ | 60.3 | _65.7_ | _99.8_ | 75.3 \n",
      "| **Avg.** | **67.6** | **64.6** | **62.0** | **63.3** | **72.4** | **68.6** | **70.4** | **70.7** | **70.5** | **61.6** | **65.6** | **99.3** | **75.5** |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "\n",
    "## PRMs\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(prm_model_name_dict.keys()))\n",
    "prm_str = get_res_str(prm_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += prm_str\n",
    "\n",
    "## Close Models\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(close_model_name_dict.keys()))\n",
    "close_str = get_res_str(close_model_name_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += close_str\n",
    "\n",
    "\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form HTML str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm_model_dict = {\n",
    "    \"skyworkprm_1_5B\": {\"Name\": \"Skywork-PRM-1.5B\", \"Source\": \"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\", \"Class\": \"PRM\"},\n",
    "    \"skyworkprm_7B\": {\"Name\": \"Skywork-PRM-7B\", \"Source\": \"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_prm_prm800k\": {\"Name\": \"Llemma-PRM800k-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_prm_metamath\": {\"Name\": \"Llemma-MetaMath-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"llemma7b_oprm_prm800k\": {\"Name\": \"Llemma-oprm-7B\", \"Source\": \"https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf\", \"Class\": \"PRM\"},\n",
    "    \"mathminos_mistral\": {\"Name\": \"MATHMinos-Mistral-7B\", \"Source\": \"https://github.com/KbsdJames/MATH-Minos\", \"Class\": \"PRM\"},\n",
    "    \"mathshepherd\": {\"Name\": \"MathShepherd-Mistral-7B\", \"Source\": \"https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm\", \"Class\": \"PRM\"},\n",
    "    \"reasoneval7b\": {\"Name\": \"ReasonEval-7B\", \"Source\": \"https://huggingface.co/GAIR/ReasonEval-7B\", \"Class\": \"PRM\"},\n",
    "    \"llama3_1_8b_prm_mistral\": {\"Name\": \"RLHFlow-PRM-Mistral-8B\", \"Source\": \"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data\", \"Class\": \"PRM\"},\n",
    "    \"llama3_1_8b_prm_deepseek\": {\"Name\": \"RLHFlow-PRM-Deepseek-8B\", \"Source\": \"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\", \"Class\": \"PRM\"},\n",
    "    \"reasoneval34b\": {\"Name\": \"ReasonEval-34B\", \"Source\": \"https://huggingface.co/GAIR/ReasonEval-34B\", \"Class\": \"PRM\"},\n",
    "    \"gpt4o\": {\"Name\": \"GPT-4o\", \"Source\": \"https://openai.com/index/hello-gpt-4o/\", \"Class\": \"LM-C\"},\n",
    "    \"o1mini\": {\"Name\": \"o1-mini\", \"Source\": \"https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/\", \"Class\": \"LM-C\"},\n",
    "    \"gemini_2_flash\": {\"Name\": \"Gemini-2.0-flash-exp\", \"Source\": \"https://deepmind.google/technologies/gemini/flash/\", \"Class\": \"LM-C\"},\n",
    "    \"gemini_2_thinking\": {\"Name\": \"Gemini-2.0-thinking-exp-1219\", \"Source\": \"https://ai.google.dev/gemini-api/docs/thinking-mode\", \"Class\": \"LM-C\"},\n",
    "    # \"o1preview\": {\"Name\": \"o1-preview\", \"Source\": \"https://openai.com/index/introducing-openai-o1-preview/\", \"Class\": \"LM-C\"},\n",
    "    \"qwen_qwq\": {\"Name\": \"QwQ-Preview-32B\", \"Source\": \"https://huggingface.co/Qwen/QwQ-32B-Preview\", \"Class\": \"LM-O\"},\n",
    "    \"qwen_prm7b\": {\"Name\": \"Qwen2.5-Math-PRM-7B\", \"Source\": \"https://huggingface.co/Qwen/Qwen2.5-Math-PRM-7B\", \"Class\": \"PRM\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_table(model_dict, classification_dict, res_dict):\n",
    "    res_str = \"\"\n",
    "    html_str = '<table class=\"js-sort-table\" id=\"results\">\\n'\n",
    "    \n",
    "    # Ë°®Â§¥ÈÉ®ÂàÜ\n",
    "    html_str += '  <tr>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>#</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Model</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Class</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Source</strong></td>\\n'\n",
    "    html_str += '    <td class=\"js-sort-number\"><strong>Overall</strong></td>\\n'\n",
    "    \n",
    "    # Âä®ÊÄÅÁîüÊàêÂàÜÁ±ªÂàóÊ†áÈ¢ò\n",
    "    for big_classification_idx, (big_classification, current_classification_dict) in enumerate(classification_dict.items()):\n",
    "        for classification, display_classification_name in current_classification_dict.items():\n",
    "            html_str += f'    <td class=\"js-sort-number\"><strong>{display_classification_name}</strong></td>\\n'\n",
    "        html_str += f'    <td class=\"js-sort-number\"><strong>S{big_classification_idx+1}</strong></td>\\n'  # Ê∑ªÂä†Â§ßÁ±ª Avg Âàó\n",
    "    html_str += '  </tr>\\n'\n",
    "    res_str += html_str\n",
    "    sort_list = []\n",
    "    # Êï∞ÊçÆÈÉ®ÂàÜ\n",
    "    for idx, (model_k, model) in enumerate(model_dict.items()):\n",
    "        \n",
    "\n",
    "        # ËÆ°ÁÆó PRM Score\n",
    "        all_model_scores = sorted([get_prmscore_from_current_res_dict(res) for res in res_dict.values()], reverse=True)\n",
    "        current_res_dict = res_dict.get(model_k, {})\n",
    "        prm_score = get_prmscore_from_current_res_dict(current_res_dict)\n",
    "        if prm_score == all_model_scores[0]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•á</b></td>\\n'\n",
    "        elif prm_score == all_model_scores[1]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•à</b></td>\\n'\n",
    "        elif prm_score == all_model_scores[2]:\n",
    "            current_total_res_str= f'    <td><b class=\"best-score-text\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"best-score-text\">{model[\"Name\"]} ü•â</b></td>\\n'\n",
    "        else:\n",
    "            current_total_res_str= f'    <td><b class=\"\">{prm_score * 100:.1f}</b></td>\\n'\n",
    "            current_model_name_str = f'     <td><b class=\"\">{model[\"Name\"]}</b></td>\\n'\n",
    "        html_str = ''\n",
    "        html_str += '  <tr>\\n'\n",
    "        html_str += \"    <td>{CURRENT_RANK}</td>\\n\"\n",
    "        html_str += current_model_name_str\n",
    "        html_str += f'    <td>{model[\"Class\"]}</td>\\n'\n",
    "        html_str += f'    <td><a href=\"{model[\"Source\"]}\" class=\"ext-link\" target=\"_blank\">Link</a></td>\\n'\n",
    "        html_str += current_total_res_str\n",
    "        currunt_total_prm_score = prm_score\n",
    "        # ÂàÜÁ±ªÊåáÊ†áÈÉ®ÂàÜ\n",
    "        for big_classification, current_classification_dict in classification_dict.items():\n",
    "            avg = []  # ‰øùÂ≠òÂΩìÂâçÂ§ßÁ±ªÁöÑÂàÜÁ±ªÊåáÊ†áÂàÜÊï∞\n",
    "            for classification, display_classification_name in current_classification_dict.items():\n",
    "                prm_score = get_prmscore_from_current_res_dict(current_res_dict, classification)\n",
    "                avg.append(prm_score)\n",
    "                html_str += f'    <td>{prm_score * 100:.1f}</td>\\n'\n",
    "            \n",
    "            #Â§ßÁ±ªÂπ≥ÂùáÂÄº\n",
    "            avg_score = sum(avg) / len(avg) if avg else 0\n",
    "            html_str += f'    <td><b class=\"\">{avg_score * 100:.1f}</b></td>\\n'\n",
    "\n",
    "        html_str += '  </tr>\\n'\n",
    "        sort_list.append((currunt_total_prm_score, html_str))\n",
    "    sort_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    for idx,(_, html_str) in enumerate(sort_list):\n",
    "        res_str += html_str.format(CURRENT_RANK=idx+1)\n",
    "    res_str += '</table>\\n'\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"js-sort-table\" id=\"results\">\n",
      "  <tr>\n",
      "    <td class=\"js-sort-number\"><strong>#</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Model</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Class</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Source</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>Overall</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>NR.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>NCL.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S1</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>ES.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>SC.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>DC.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>CI.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S2</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>PS.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>DR.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>MS.</strong></td>\n",
      "    <td class=\"js-sort-number\"><strong>S3</strong></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>1</td>\n",
      "     <td><b class=\"best-score-text\">Gemini-2.0-thinking-exp-1219 ü•á</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://ai.google.dev/gemini-api/docs/thinking-mode\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">68.8</b></td>\n",
      "    <td>68.5</td>\n",
      "    <td>63.8</td>\n",
      "    <td><b class=\"\">66.2</b></td>\n",
      "    <td>72.9</td>\n",
      "    <td>71.3</td>\n",
      "    <td>71.0</td>\n",
      "    <td>71.8</td>\n",
      "    <td><b class=\"\">71.8</b></td>\n",
      "    <td>60.3</td>\n",
      "    <td>65.7</td>\n",
      "    <td>99.8</td>\n",
      "    <td><b class=\"\">75.3</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>2</td>\n",
      "     <td><b class=\"best-score-text\">o1-mini ü•à</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">68.8</b></td>\n",
      "    <td>65.6</td>\n",
      "    <td>63.7</td>\n",
      "    <td><b class=\"\">64.6</b></td>\n",
      "    <td>74.5</td>\n",
      "    <td>67.7</td>\n",
      "    <td>73.8</td>\n",
      "    <td>72.3</td>\n",
      "    <td><b class=\"\">72.1</b></td>\n",
      "    <td>61.8</td>\n",
      "    <td>64.8</td>\n",
      "    <td>100.0</td>\n",
      "    <td><b class=\"\">75.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>3</td>\n",
      "     <td><b class=\"best-score-text\">GPT-4o ü•â</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://openai.com/index/hello-gpt-4o/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"best-score-text\">66.8</b></td>\n",
      "    <td>57.0</td>\n",
      "    <td>62.4</td>\n",
      "    <td><b class=\"\">59.7</b></td>\n",
      "    <td>72.0</td>\n",
      "    <td>69.7</td>\n",
      "    <td>70.7</td>\n",
      "    <td>71.1</td>\n",
      "    <td><b class=\"\">70.9</b></td>\n",
      "    <td>62.5</td>\n",
      "    <td>65.7</td>\n",
      "    <td>99.2</td>\n",
      "    <td><b class=\"\">75.8</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>4</td>\n",
      "     <td><b class=\"\">Gemini-2.0-flash-exp</b></td>\n",
      "    <td>LM-C</td>\n",
      "    <td><a href=\"https://deepmind.google/technologies/gemini/flash/\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "    <td>67.2</td>\n",
      "    <td>58.1</td>\n",
      "    <td><b class=\"\">62.7</b></td>\n",
      "    <td>70.4</td>\n",
      "    <td>65.7</td>\n",
      "    <td>66.0</td>\n",
      "    <td>67.3</td>\n",
      "    <td><b class=\"\">67.3</b></td>\n",
      "    <td>61.8</td>\n",
      "    <td>66.2</td>\n",
      "    <td>98.2</td>\n",
      "    <td><b class=\"\">75.4</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>5</td>\n",
      "     <td><b class=\"\">QwQ-Preview-32B</b></td>\n",
      "    <td>LM-O</td>\n",
      "    <td><a href=\"https://huggingface.co/Qwen/QwQ-32B-Preview\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">63.6</b></td>\n",
      "    <td>57.2</td>\n",
      "    <td>55.6</td>\n",
      "    <td><b class=\"\">56.4</b></td>\n",
      "    <td>67.4</td>\n",
      "    <td>72.3</td>\n",
      "    <td>66.2</td>\n",
      "    <td>66.9</td>\n",
      "    <td><b class=\"\">68.2</b></td>\n",
      "    <td>57.8</td>\n",
      "    <td>62.7</td>\n",
      "    <td>100.0</td>\n",
      "    <td><b class=\"\">73.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>6</td>\n",
      "     <td><b class=\"\">ReasonEval-34B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/GAIR/ReasonEval-34B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">60.5</b></td>\n",
      "    <td>54.8</td>\n",
      "    <td>48.1</td>\n",
      "    <td><b class=\"\">51.5</b></td>\n",
      "    <td>66.4</td>\n",
      "    <td>60.3</td>\n",
      "    <td>57.8</td>\n",
      "    <td>67.5</td>\n",
      "    <td><b class=\"\">63.0</b></td>\n",
      "    <td>57.7</td>\n",
      "    <td>64.3</td>\n",
      "    <td>97.2</td>\n",
      "    <td><b class=\"\">73.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>7</td>\n",
      "     <td><b class=\"\">ReasonEval-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/GAIR/ReasonEval-7B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">60.0</b></td>\n",
      "    <td>61.0</td>\n",
      "    <td>50.1</td>\n",
      "    <td><b class=\"\">55.6</b></td>\n",
      "    <td>62.1</td>\n",
      "    <td>65.9</td>\n",
      "    <td>61.5</td>\n",
      "    <td>65.9</td>\n",
      "    <td><b class=\"\">63.8</b></td>\n",
      "    <td>55.6</td>\n",
      "    <td>57.9</td>\n",
      "    <td>99.5</td>\n",
      "    <td><b class=\"\">71.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>8</td>\n",
      "     <td><b class=\"\">RLHFlow-PRM-Mistral-8B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Mistral-Data\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.4</b></td>\n",
      "    <td>46.1</td>\n",
      "    <td>47.3</td>\n",
      "    <td><b class=\"\">46.7</b></td>\n",
      "    <td>56.6</td>\n",
      "    <td>55.1</td>\n",
      "    <td>54.4</td>\n",
      "    <td>63.8</td>\n",
      "    <td><b class=\"\">57.5</b></td>\n",
      "    <td>51.5</td>\n",
      "    <td>56.2</td>\n",
      "    <td>97.9</td>\n",
      "    <td><b class=\"\">68.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>9</td>\n",
      "     <td><b class=\"\">RLHFlow-PRM-Deepseek-8B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/RLHFlow/Llama3.1-8B-PRM-Deepseek-Data\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.2</b></td>\n",
      "    <td>46.4</td>\n",
      "    <td>48.9</td>\n",
      "    <td><b class=\"\">47.6</b></td>\n",
      "    <td>55.7</td>\n",
      "    <td>55.0</td>\n",
      "    <td>53.2</td>\n",
      "    <td>66.2</td>\n",
      "    <td><b class=\"\">57.5</b></td>\n",
      "    <td>49.0</td>\n",
      "    <td>55.4</td>\n",
      "    <td>99.8</td>\n",
      "    <td><b class=\"\">68.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>10</td>\n",
      "     <td><b class=\"\">MATHMinos-Mistral-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://github.com/KbsdJames/MATH-Minos\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">54.2</b></td>\n",
      "    <td>48.8</td>\n",
      "    <td>54.0</td>\n",
      "    <td><b class=\"\">51.4</b></td>\n",
      "    <td>57.0</td>\n",
      "    <td>52.1</td>\n",
      "    <td>50.7</td>\n",
      "    <td>57.8</td>\n",
      "    <td><b class=\"\">54.4</b></td>\n",
      "    <td>52.8</td>\n",
      "    <td>55.8</td>\n",
      "    <td>91.1</td>\n",
      "    <td><b class=\"\">66.5</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>11</td>\n",
      "     <td><b class=\"\">Llemma-PRM800k-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-prm-prm800k-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">52.0</b></td>\n",
      "    <td>49.3</td>\n",
      "    <td>53.4</td>\n",
      "    <td><b class=\"\">51.4</b></td>\n",
      "    <td>56.4</td>\n",
      "    <td>47.1</td>\n",
      "    <td>46.7</td>\n",
      "    <td>53.3</td>\n",
      "    <td><b class=\"\">50.9</b></td>\n",
      "    <td>51.0</td>\n",
      "    <td>53.5</td>\n",
      "    <td>93.6</td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>12</td>\n",
      "     <td><b class=\"\">Llemma-MetaMath-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-prm-metamath-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">50.5</b></td>\n",
      "    <td>50.2</td>\n",
      "    <td>50.5</td>\n",
      "    <td><b class=\"\">50.3</b></td>\n",
      "    <td>51.9</td>\n",
      "    <td>47.6</td>\n",
      "    <td>44.4</td>\n",
      "    <td>52.1</td>\n",
      "    <td><b class=\"\">49.0</b></td>\n",
      "    <td>50.5</td>\n",
      "    <td>51.3</td>\n",
      "    <td>96.0</td>\n",
      "    <td><b class=\"\">66.0</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>13</td>\n",
      "     <td><b class=\"\">Llemma-oprm-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/ScalableMath/llemma-7b-oprm-prm800k-level-1to3-hf\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">50.3</b></td>\n",
      "    <td>48.7</td>\n",
      "    <td>49.3</td>\n",
      "    <td><b class=\"\">49.0</b></td>\n",
      "    <td>54.2</td>\n",
      "    <td>46.8</td>\n",
      "    <td>44.5</td>\n",
      "    <td>53.5</td>\n",
      "    <td><b class=\"\">49.8</b></td>\n",
      "    <td>49.2</td>\n",
      "    <td>51.3</td>\n",
      "    <td>91.8</td>\n",
      "    <td><b class=\"\">64.1</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>14</td>\n",
      "     <td><b class=\"\">MathShepherd-Mistral-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/peiyi9979/math-shepherd-mistral-7b-prm\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">47.0</b></td>\n",
      "    <td>44.0</td>\n",
      "    <td>50.3</td>\n",
      "    <td><b class=\"\">47.1</b></td>\n",
      "    <td>49.4</td>\n",
      "    <td>44.5</td>\n",
      "    <td>41.3</td>\n",
      "    <td>47.7</td>\n",
      "    <td><b class=\"\">45.7</b></td>\n",
      "    <td>47.2</td>\n",
      "    <td>48.6</td>\n",
      "    <td>86.1</td>\n",
      "    <td><b class=\"\">60.7</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>15</td>\n",
      "     <td><b class=\"\">Skywork-PRM-7B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-7B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">36.2</b></td>\n",
      "    <td>35.7</td>\n",
      "    <td>41.2</td>\n",
      "    <td><b class=\"\">38.4</b></td>\n",
      "    <td>36.7</td>\n",
      "    <td>29.1</td>\n",
      "    <td>30.6</td>\n",
      "    <td>34.4</td>\n",
      "    <td><b class=\"\">32.7</b></td>\n",
      "    <td>36.8</td>\n",
      "    <td>37.4</td>\n",
      "    <td>88.8</td>\n",
      "    <td><b class=\"\">54.3</b></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>16</td>\n",
      "     <td><b class=\"\">Skywork-PRM-1.5B</b></td>\n",
      "    <td>PRM</td>\n",
      "    <td><a href=\"https://huggingface.co/Skywork/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\" class=\"ext-link\" target=\"_blank\">Link</a></td>\n",
      "    <td><b class=\"\">31.7</b></td>\n",
      "    <td>31.4</td>\n",
      "    <td>35.8</td>\n",
      "    <td><b class=\"\">33.6</b></td>\n",
      "    <td>32.4</td>\n",
      "    <td>25.7</td>\n",
      "    <td>26.0</td>\n",
      "    <td>30.2</td>\n",
      "    <td><b class=\"\">28.6</b></td>\n",
      "    <td>33.1</td>\n",
      "    <td>32.3</td>\n",
      "    <td>81.1</td>\n",
      "    <td><b class=\"\">48.8</b></td>\n",
      "  </tr>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_str = \"\"\n",
    "\n",
    "\n",
    "## PRMs\n",
    "res_dict = get_res_dict(file_dict,model_lists=list(prm_model_dict.keys()))\n",
    "prm_str = get_html_table(prm_model_dict, classification_parallel_dict, res_dict,)\n",
    "res_str += prm_str\n",
    "\n",
    "\n",
    "\n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
